# paper-reactor

ç§‘æŠ€è®ºæ–‡çš„ä¸‹è½½ã€æ•°æ®æ¸…æ´—ä¸ä¿¡æ¯æå–ï¼Œè¯•ç€ç¢°æ’ä¸€ä¸‹å¥½ç©çš„æ€è·¯ğŸ’¥


## Paper-Pipeline Design

è¿™æ˜¯æœ€å®Œæ•´çš„æµç¨‹è®¾è®¡ï¼Œä¸åŒçš„æœŸåˆŠå’Œå¤„ç†ç›®çš„ï¼Œå¯ä»¥è·³è¿‡å…¶ä¸­ä¸€äº›æ­¥éª¤ã€‚

1. downloader(including parsering)
2. cleaner
3. normalizer
4. filler
5. merger
6. sinker

#### nature.com pipeline

```bash
# download new papers
python3 downloader/nature_downloaders/download_nature.py
# translate using google API
proxychains4 -q python3 filler/translator/trans_papers.py
# merge issuely files into one
python3 merger/nature/merge_issuely_csv_files.py
```

analysis

```bash
python3 analyzer/topic_photonics/data_insights/list_paper_types.py > docs/nature/contentType-list.md
```

upload to é»‘å¸•äº‘

æ¸£æ¸£ APIï¼Œå¤§çº¦éœ€è¦ç­‰å¾… 30 min æ‰èƒ½ä¸Šä¼  5000 æ¡æ•°æ®ã€‚

```bash
python3 tools/upload_papers_to_hipacloud.py
```

ä¸‹é¢çš„æ–¹æ³•ï¼Œæ•ˆç‡æ›´ä½ï¼Œæ”¾å¼ƒã€‚

```bash
rm -rf tmp-data && mkdir tmp-data && split -l 520 paper-data/merged/nature/nature_papers_merged_long_paper.csv tmp-data/long_paper_part
```

ç½‘ç«™çš„å¯¼å…¥èƒ½åŠ›æå·®ï¼Œå…ˆè‹Ÿä¸€ä¸‹ã€‚

```bash
# list article type
python3 analyzer/topic_photonics/data_insights/list_paper_types.py > docs/nature/contentType-list.md
```

ç¿»è¯‘é€Ÿåº¦ï¼š

1. è°ƒç”¨ Google translate APIï¼Œå®‰å…¨èµ·è§ï¼Œé—´éš” 5 ç§’ã€‚
2. ä¸€ç¯‡æ–‡ç« ç¿»è¯‘ 2 ä¸ªå­—æ®µ ï¼štitle/abstractï¼Œéœ€ 10 ç§’ã€‚
3. ä¸€å°æ—¶å¯ä»¥ç¿»è¯‘ 360 ç¯‡æ–‡ç« ã€‚å…¨é‡æ–‡ç« å…± 10k ç¯‡ï¼Œå¤§çº¦éœ€è¦ 30 å°æ—¶ã€‚


## Setup

```bash
pip3 install -r requirements.txt
```
